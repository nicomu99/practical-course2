{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset Overview",
   "id": "58d601e0831c0546"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-24T10:01:40.770710Z",
     "start_time": "2025-02-24T10:01:40.327288Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:05:24.409249Z",
     "start_time": "2025-02-24T10:05:23.489409Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_parquet('data/agent_compt.parquet')",
   "id": "28189821d1311c44",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:30:44.468355Z",
     "start_time": "2025-02-24T10:30:44.397996Z"
    }
   },
   "cell_type": "code",
   "source": "data.info()",
   "id": "d666b779eb7cca6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175112 entries, 0 to 175111\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   dataset       175112 non-null  object\n",
      " 1   category      175112 non-null  object\n",
      " 2   input         175112 non-null  object\n",
      " 3   agent         153220 non-null  object\n",
      " 4   response      175090 non-null  object\n",
      " 5   ground_truth  175112 non-null  object\n",
      " 6   pred          175112 non-null  object\n",
      " 7   score         175112 non-null  int64 \n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:05:54.235630Z",
     "start_time": "2025-02-24T10:05:54.223596Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "id": "a09308a93076c5d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    dataset    category                                              input  \\\n",
       "0  mmlu_pro  philosophy  \" _Ad crumenam_ \" is a specific kind of\\n(A) S...   \n",
       "1  mmlu_pro  philosophy  \" _Ad crumenam_ \" is a specific kind of\\n(A) S...   \n",
       "2  mmlu_pro  philosophy  \" _Ad crumenam_ \" is a specific kind of\\n(A) S...   \n",
       "3  mmlu_pro  philosophy  \" _Ad crumenam_ \" is a specific kind of\\n(A) S...   \n",
       "4  mmlu_pro  philosophy  \" _Ad crumenam_ \" is a specific kind of\\n(A) S...   \n",
       "\n",
       "                                               agent  \\\n",
       "0  You are a logician, proficient in identifying ...   \n",
       "1                                               None   \n",
       "2  You are a classicist, perhaps with a focus on ...   \n",
       "3  You are a classical scholar, specializing in a...   \n",
       "4  You are a Latin expert, familiar with the nuan...   \n",
       "\n",
       "                                            response ground_truth pred  score  \n",
       "0  The correct answer is **(I) Red Herring**. Her...            C    I      0  \n",
       "1  The correct answer is **(C) False sign**.\\n\\nH...            C    C      1  \n",
       "2  The Latin phrase \"_Ad crumenam_\" translates to...            C    C      1  \n",
       "3  The correct answer is **(C) False sign**. Here...            C    C      1  \n",
       "4  The correct answer is **(C) False sign**. Here...            C    C      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>category</th>\n",
       "      <th>input</th>\n",
       "      <th>agent</th>\n",
       "      <th>response</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mmlu_pro</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>\" _Ad crumenam_ \" is a specific kind of\\n(A) S...</td>\n",
       "      <td>You are a logician, proficient in identifying ...</td>\n",
       "      <td>The correct answer is **(I) Red Herring**. Her...</td>\n",
       "      <td>C</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mmlu_pro</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>\" _Ad crumenam_ \" is a specific kind of\\n(A) S...</td>\n",
       "      <td>None</td>\n",
       "      <td>The correct answer is **(C) False sign**.\\n\\nH...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mmlu_pro</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>\" _Ad crumenam_ \" is a specific kind of\\n(A) S...</td>\n",
       "      <td>You are a classicist, perhaps with a focus on ...</td>\n",
       "      <td>The Latin phrase \"_Ad crumenam_\" translates to...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mmlu_pro</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>\" _Ad crumenam_ \" is a specific kind of\\n(A) S...</td>\n",
       "      <td>You are a classical scholar, specializing in a...</td>\n",
       "      <td>The correct answer is **(C) False sign**. Here...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mmlu_pro</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>\" _Ad crumenam_ \" is a specific kind of\\n(A) S...</td>\n",
       "      <td>You are a Latin expert, familiar with the nuan...</td>\n",
       "      <td>The correct answer is **(C) False sign**. Here...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The dataset contains tuples of prompts, agent descriptions and responses, as well as a score indicating whether the answer is correct or not.",
   "id": "738faacba03cb880"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Datasets",
   "id": "604ec55a4794dcd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:06:26.588326Z",
     "start_time": "2025-02-24T10:06:26.575590Z"
    }
   },
   "cell_type": "code",
   "source": "data['dataset'].unique()",
   "id": "1a18985cae8aebe7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mmlu_pro', 'bigbench', 'truthfulqa'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Measuring Massive Multitask Language Understanding Pro (MMLU-Pro)\n",
    "    - benchmark for evaluating LLMs\n",
    "    - obv. for multitask learning and language understanding\n",
    "    - a more challenging benchmark than MMLU with reasoning-focused questions and more answers choices per question (10 instead of 4)\n",
    "    - 12 000 questions from academic exams and textbooks spanning domains including Natural Sciences, Business, CS, Engineering, Econ, Law, Math...\n",
    "- Beyond Imitation Game Benchmark (BIG-bench)\n",
    "    - More than 200 different LLM tasks in one benchmark\n",
    "        - Traditional NLP tasks: word disambiguation, contextual qa, reading comprehension\n",
    "        - Logic, math and code: algorithms, logical reasoning, algebra\n",
    "        - Understanding the world: causal reasoning, consistent identity\n",
    "        - And much, much more (https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/keywords_to_tasks.md#summary-table)\n",
    "    - Multilanguage\n",
    "    - Maintained by Google\n",
    "- TruthfulQA\n",
    "    - \"Assess the accuracy of LLMs in answering questions truthfully\"\n",
    "    - 817 questions from 38 topics (health, law, finance, politics...)\n",
    "    - Questions target common misconceptions, which humans would likely answer false\n",
    "    - Tasks:\n",
    "        - Generation task: Given a question, answer in 1-2 sentences\n",
    "        - MC: Either with single choice or true multiple choice"
   ],
   "id": "f680990eadc8cd81"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Categories",
   "id": "874db878ff1f7fb3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Appears to be the category of the task the model should perform.",
   "id": "82b9457a072f8404"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:29:13.500699Z",
     "start_time": "2025-02-24T10:29:13.486177Z"
    }
   },
   "cell_type": "code",
   "source": "len(data['category'].unique())",
   "id": "c9ece0c0b7da6ed5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:28:55.357485Z",
     "start_time": "2025-02-24T10:28:55.342704Z"
    }
   },
   "cell_type": "code",
   "source": "sorted(data['category'].unique())",
   "id": "87e75b7ffc40fd0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_narrative_understanding',\n",
       " 'anachronisms',\n",
       " 'analogical_similarity',\n",
       " 'arithmetic',\n",
       " 'biology',\n",
       " 'business',\n",
       " 'causal_judgment',\n",
       " 'cause_and_effect',\n",
       " 'checkmate_in_one',\n",
       " 'chemistry',\n",
       " 'cifar10_classification',\n",
       " 'color',\n",
       " 'computer science',\n",
       " 'contextual_parametric_knowledge_conflicts',\n",
       " 'cs_algorithms',\n",
       " 'discourse_marker_prediction',\n",
       " 'economics',\n",
       " 'elementary_math_qa',\n",
       " 'engineering',\n",
       " 'epistemic_reasoning',\n",
       " 'fact_checker',\n",
       " 'fantasy_reasoning',\n",
       " 'formal_fallacies_syllogisms_negation',\n",
       " 'goal_step_wikihow',\n",
       " 'health',\n",
       " 'hhh_alignment',\n",
       " 'hindu_knowledge',\n",
       " 'hinglish_toxicity',\n",
       " 'history',\n",
       " 'implicatures',\n",
       " 'indic_cause_and_effect',\n",
       " 'intent_recognition',\n",
       " 'kanji_ascii',\n",
       " 'kannada',\n",
       " 'language_identification',\n",
       " 'law',\n",
       " 'logic_grid_puzzle',\n",
       " 'logical_deduction',\n",
       " 'logical_fallacy_detection',\n",
       " 'math',\n",
       " 'medical_questions_russian',\n",
       " 'metaphor_boolean',\n",
       " 'metaphor_understanding',\n",
       " 'misconceptions',\n",
       " 'mnist_ascii',\n",
       " 'moral_permissibility',\n",
       " 'movie_dialog_same_or_different',\n",
       " 'other',\n",
       " 'parsinlu_qa',\n",
       " 'philosophy',\n",
       " 'physics',\n",
       " 'play_dialog_same_or_different',\n",
       " 'presuppositions_as_nli',\n",
       " 'psychology',\n",
       " 'question_selection',\n",
       " 'real_or_fake_text',\n",
       " 'rhyming',\n",
       " 'social_iqa',\n",
       " 'social_support',\n",
       " 'strange_stories',\n",
       " 'strategyqa',\n",
       " 'swahili_english_proverbs',\n",
       " 'symbol_interpretation',\n",
       " 'timedial',\n",
       " 'tracking_shuffled_objects',\n",
       " 'truthfulqa',\n",
       " 'understanding_fables',\n",
       " 'undo_permutation',\n",
       " 'unit_conversion',\n",
       " 'vitaminc_fact_verification',\n",
       " 'which_wiki_edit',\n",
       " 'winowhy']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Input",
   "id": "b3ead2afb25204fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The input passed to the model. For the model, this includes all information, including the task it should solve, answer possibilities for MC tasks and so on.",
   "id": "9b284b85c7f391bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:38:14.834398Z",
     "start_time": "2025-02-24T10:38:14.828449Z"
    }
   },
   "cell_type": "code",
   "source": "data['input'][0]",
   "id": "55ba2ff07d1d59be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" _Ad crumenam_ \" is a specific kind of\\n(A) Slippery Slope\\n(B) Hasty Conclusion\\n(C) False sign\\n(D) False analogy\\n(E) Bandwagon Fallacy\\n(F) Circular Reasoning\\n(G) Hasty Generalization\\n(H) Straw Man Fallacy\\n(I) Red Herring<end_of_turn>\\n<start_of_turn>model\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:41:33.396520Z",
     "start_time": "2025-02-24T10:41:33.375242Z"
    }
   },
   "cell_type": "code",
   "source": "data['input'].value_counts().unique()",
   "id": "8c223e73e4cafa17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Either 8 or 16 answers per prompt.",
   "id": "df727815d6bd52a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:37:48.331968Z",
     "start_time": "2025-02-24T10:37:48.141188Z"
    }
   },
   "cell_type": "code",
   "source": "f\"On average, there are {len(data) / len(data['input'].unique())} answers per prompt\"",
   "id": "6de1f4dcffddfb25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On average, there are 8.058536585365854 answers per prompt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Agent (also called persona)",
   "id": "c0734d39e59e6706"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Each answer to a given prompt is answered by making the model act as a certain persona.",
   "id": "331722346473cb08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:43:34.347882Z",
     "start_time": "2025-02-24T10:43:34.329053Z"
    }
   },
   "cell_type": "code",
   "source": "data[data['input'] == data['input'][0]]['agent']",
   "id": "4a22b4ffad6a6e4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    You are a logician, proficient in identifying ...\n",
       "1                                                 None\n",
       "2    You are a classicist, perhaps with a focus on ...\n",
       "3    You are a classical scholar, specializing in a...\n",
       "4    You are a Latin expert, familiar with the nuan...\n",
       "5    You are a student of logic and rhetoric, well-...\n",
       "6    You are a klassically trained historian specia...\n",
       "7    You are a scholar specializing in ancient Roma...\n",
       "Name: agent, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The dataset includes no specific information about whether these personas are advantageous, disadvantageous or neutral. However, one might assume some are better suited for tasks than others. In the above example, all personas seem to be advantageous.",
   "id": "9552dcbd552b619d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Response, Ground Truth, Pred and Score",
   "id": "8f5ce82d9d1f5629"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The response is the output of the LLM in prose:",
   "id": "1c6b920244c8a0ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:51:06.535085Z",
     "start_time": "2025-02-24T10:51:06.529544Z"
    }
   },
   "cell_type": "code",
   "source": "data['response'][0]",
   "id": "3cc288ec1e9daa47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The correct answer is **(I) Red Herring**. Here\\'s why:\\n\\n* **_Ad crumenam_** is a Latin term that translates to \"to the purse\".  It\\'s a fallacy where someone tries to deflect from the real issue by introducing an irrelevant appeal to wealth or financial gain.\\n\\nLet\\'s break down why the other options are incorrect:\\n\\n* **(A) Slippery Slope:**  This fallacy assumes a chain reaction of negative events will occur when something initially happens, without sufficient evidence.\\n* **(B) Hasty Conclusion:** Drawing a conclusion based on insufficient or biased evidence.\\n* **(C) False Sign:** Mistaking a correlation for causation.\\n* **(D) False Analogy:**  Comparing two things that are not truly alike to make a flawed argument.\\n* **(E) Bandwagon Fallacy:** Arguing that something must be true because many people believe it.\\n* **(F) Circular Reasoning:**  Restating the conclusion as part of the premise.\\n* **(G) Hasty Generalization:** Making a broad generalization based on a small or unrepresentative sample.\\n* **(H) Straw Man Fallacy:**  Misrepresenting an opponent\\'s argument to make it easier to attack.\\n\\n\\n**In summary:** _Ad crumenam_ is specifically about using money as a distraction to avoid addressing the core argument. \\n\\n\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Whereas ground truth and pred only contain the answer character:",
   "id": "a079cf1c90a4e92a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:52:15.484611Z",
     "start_time": "2025-02-24T10:52:15.473275Z"
    }
   },
   "cell_type": "code",
   "source": "data['ground_truth'].unique()",
   "id": "a3f1507118b67313",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'A', 'D', 'B', 'F', 'G', 'I', 'J', 'E', 'H', 'K', 'P', 'W',\n",
       "       'Y', 'N', 'U', 'O', 'L', 'M', 'Q', 'S', 'T'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:52:27.948346Z",
     "start_time": "2025-02-24T10:52:27.938556Z"
    }
   },
   "cell_type": "code",
   "source": "data['pred'].unique()",
   "id": "f73a25dfc57a5235",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', 'C', 'A', 'D', 'J', 'B', '-1', 'F', 'H', 'E', 'G', 'K', 'P',\n",
       "       'W', 'Z', 'Y', 'N', 'Q', 'L', 'U', 'O', 'M', 'T', 'S'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Score is a boolean indicating whether the answer is correct or not.",
   "id": "c1ea7d6cb89cf853"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T10:49:58.443941Z",
     "start_time": "2025-02-24T10:49:58.437421Z"
    }
   },
   "cell_type": "code",
   "source": "data['score'].unique()",
   "id": "790a7549c0ba0f91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:18:01.411244Z",
     "start_time": "2025-02-24T11:17:56.658253Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data = data[data.groupby('input')['score'].transform(lambda x: (x == 1).sum()) == 1]",
   "id": "8f6f55822cab12e2",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:19:23.984283Z",
     "start_time": "2025-02-24T11:19:23.979997Z"
    }
   },
   "cell_type": "code",
   "source": "len(filtered_data)",
   "id": "ed10f11ca99b915",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13984"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:20:04.207809Z",
     "start_time": "2025-02-24T11:20:04.202728Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data['input'][224]",
   "id": "49fad47d2a48d225",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"The hubZOffset can be used to``sink\"\"the hub into the wheel, and it defaults to half the wheel thickness.\"\\n  choice: Regardless, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n  choice: For example when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n  choice: Instead, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n  choice: Conversely when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n  choice: Meantime, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n  choice: However when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n  choice: Slowly, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n  choice: Initially, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n  choice: Importantly, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n  choice: Later, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(A) However when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(B) Conversely when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(C) Initially, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(D) Importantly, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(E) Instead, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(F) Regardless, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(G) Slowly, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(H) Meantime, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(I) For example when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.\\n(J) Later, when the hubHeight is 10 and the hubZOffset is -2, then the hub will protrude 8mm from the wheel, but the shaft hole will be 10mm deep.<end_of_turn>\\n<start_of_turn>model\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T11:19:15.827576Z",
     "start_time": "2025-02-24T11:19:15.812496Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data[filtered_data['input'] == filtered_data['input'][224]]",
   "id": "2069f9e6d01538f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      dataset                     category  \\\n",
       "224  bigbench  discourse_marker_prediction   \n",
       "225  bigbench  discourse_marker_prediction   \n",
       "226  bigbench  discourse_marker_prediction   \n",
       "227  bigbench  discourse_marker_prediction   \n",
       "228  bigbench  discourse_marker_prediction   \n",
       "229  bigbench  discourse_marker_prediction   \n",
       "230  bigbench  discourse_marker_prediction   \n",
       "231  bigbench  discourse_marker_prediction   \n",
       "\n",
       "                                                 input  \\\n",
       "224  \"The hubZOffset can be used to``sink\"\"the hub ...   \n",
       "225  \"The hubZOffset can be used to``sink\"\"the hub ...   \n",
       "226  \"The hubZOffset can be used to``sink\"\"the hub ...   \n",
       "227  \"The hubZOffset can be used to``sink\"\"the hub ...   \n",
       "228  \"The hubZOffset can be used to``sink\"\"the hub ...   \n",
       "229  \"The hubZOffset can be used to``sink\"\"the hub ...   \n",
       "230  \"The hubZOffset can be used to``sink\"\"the hub ...   \n",
       "231  \"The hubZOffset can be used to``sink\"\"the hub ...   \n",
       "\n",
       "                                                 agent  \\\n",
       "224                                               None   \n",
       "225  You are a technical expert familiar with mecha...   \n",
       "226  You are an expert in 3D modeling and understan...   \n",
       "227  You are a person with a deep understanding of ...   \n",
       "228  You are a person knowledgeable about 3D modeli...   \n",
       "229  You are an engineer who understands 3D modelin...   \n",
       "230  You are a 3D modeling expert,  familiar with t...   \n",
       "231  You are a technical writer specializing in 3D ...   \n",
       "\n",
       "                                              response ground_truth pred  \\\n",
       "224  The best choice to complete the sentence is **...            I    E   \n",
       "225  The best option here is **(I) For example when...            I    I   \n",
       "226  The best choice here is either **(E) Instead, ...            I    E   \n",
       "227  The best choice here is **(E) Instead, when th...            I    E   \n",
       "228  The correct answer is **(E), **Instead, when t...            I    E   \n",
       "229  The answer is **(E) Instead, when the hubHeigh...            I    E   \n",
       "230  The best answer here is **(E) Instead, when th...            I    E   \n",
       "231  The best choice from the options provided is *...            I    E   \n",
       "\n",
       "     score  \n",
       "224      0  \n",
       "225      1  \n",
       "226      0  \n",
       "227      0  \n",
       "228      0  \n",
       "229      0  \n",
       "230      0  \n",
       "231      0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>category</th>\n",
       "      <th>input</th>\n",
       "      <th>agent</th>\n",
       "      <th>response</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>bigbench</td>\n",
       "      <td>discourse_marker_prediction</td>\n",
       "      <td>\"The hubZOffset can be used to``sink\"\"the hub ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The best choice to complete the sentence is **...</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>bigbench</td>\n",
       "      <td>discourse_marker_prediction</td>\n",
       "      <td>\"The hubZOffset can be used to``sink\"\"the hub ...</td>\n",
       "      <td>You are a technical expert familiar with mecha...</td>\n",
       "      <td>The best option here is **(I) For example when...</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>bigbench</td>\n",
       "      <td>discourse_marker_prediction</td>\n",
       "      <td>\"The hubZOffset can be used to``sink\"\"the hub ...</td>\n",
       "      <td>You are an expert in 3D modeling and understan...</td>\n",
       "      <td>The best choice here is either **(E) Instead, ...</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>bigbench</td>\n",
       "      <td>discourse_marker_prediction</td>\n",
       "      <td>\"The hubZOffset can be used to``sink\"\"the hub ...</td>\n",
       "      <td>You are a person with a deep understanding of ...</td>\n",
       "      <td>The best choice here is **(E) Instead, when th...</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>bigbench</td>\n",
       "      <td>discourse_marker_prediction</td>\n",
       "      <td>\"The hubZOffset can be used to``sink\"\"the hub ...</td>\n",
       "      <td>You are a person knowledgeable about 3D modeli...</td>\n",
       "      <td>The correct answer is **(E), **Instead, when t...</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>bigbench</td>\n",
       "      <td>discourse_marker_prediction</td>\n",
       "      <td>\"The hubZOffset can be used to``sink\"\"the hub ...</td>\n",
       "      <td>You are an engineer who understands 3D modelin...</td>\n",
       "      <td>The answer is **(E) Instead, when the hubHeigh...</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>bigbench</td>\n",
       "      <td>discourse_marker_prediction</td>\n",
       "      <td>\"The hubZOffset can be used to``sink\"\"the hub ...</td>\n",
       "      <td>You are a 3D modeling expert,  familiar with t...</td>\n",
       "      <td>The best answer here is **(E) Instead, when th...</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>bigbench</td>\n",
       "      <td>discourse_marker_prediction</td>\n",
       "      <td>\"The hubZOffset can be used to``sink\"\"the hub ...</td>\n",
       "      <td>You are a technical writer specializing in 3D ...</td>\n",
       "      <td>The best choice from the options provided is *...</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ae7052f903c7a28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
